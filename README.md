# ğŸ–¼ï¸ Image Sharpening using Knowledge Distillation

This project implements a deep learning pipeline for sharpening blurry images using Knowledge Distillation (KD). A powerful **Teacher** model transfers its learned features to a lightweight **Student** model for efficient deployment.

## ğŸ“Œ Goal
Train a small model that can convert blurry images into sharp ones, mimicking the output of a high-capacity model.

## ğŸ§  Concepts Used
- **Knowledge Distillation**
- **Image Deblurring/Sharpening**
- **Perceptual & Feature Distillation Losses**

## ğŸ”§ Architecture Overview
- **Teacher Model**: Restormer / SwinIR / MPRNet (pretrained)
- **Student Model**: Lightweight CNN or UNet
- **Loss Functions**:
  - L1 Reconstruction Loss
  - Perceptual Loss (VGG-based)
  - Feature Distillation Loss
  - (Optional) Edge/Gradient Loss

## ğŸ“‚ Dataset
You can use datasets like:
- GoPro Deblurring Dataset
- REDS Dataset
- DIV2K
- Folder Structure
```
  image-sharpening-kd/
â”œâ”€â”€ models/               # (optional) contains teacher and student models
â”‚   â”œâ”€â”€ teacher.py
â”‚   â””â”€â”€ student.py
â”œâ”€â”€ data/                 # (optional) sample images or instructions to download datasets
â”œâ”€â”€ utils/                # (optional) helper functions (losses, transforms)
â”œâ”€â”€ IMAGE SHARPENING USING KNOWLEDGE DISTILLATION.ipynb
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
## ğŸš€ How to Run
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
